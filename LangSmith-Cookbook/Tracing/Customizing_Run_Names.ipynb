{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = os.environ['OPENAI_API_VERSION']\n",
    "\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'customizing_run_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ•ðŸŒ”ðŸŒ“ðŸŒ’ðŸŒ‘"
     ]
    }
   ],
   "source": [
    "from langchain import prompts, callbacks, schema\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(temperature=0.0,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    deployment_name=\"gpt-35-turbo-16k\",\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type = openai.api_type,\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompts.ChatPromptTemplate.from_template(\"Reverse the following string: {text}\")\n",
    "    | model\n",
    ").with_config({\"run_name\": \"StringReverse\"})\n",
    "\n",
    "with callbacks.collect_runs() as cb:\n",
    "    for chunk in chain.stream({\"text\": \"ðŸŒ‘ðŸŒ’ðŸŒ“ðŸŒ”ðŸŒ•\"}):\n",
    "        print(chunk.content, flush=True, end=\"\")\n",
    "    run = cb.traced_runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StringReverse'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': AIMessageChunk(content='ðŸŒ•ðŸŒ”ðŸŒ“ðŸŒ’ðŸŒ‘')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id=UUID('6a802275-a598-461f-98c1-966bf902c25c'), name='StringReverse', start_time=datetime.datetime(2023, 12, 4, 3, 25, 26, 160888), run_type='chain', end_time=datetime.datetime(2023, 12, 4, 3, 25, 28, 311379), extra={'runtime': {'cpu': {'time': {'sys': 0.546875, 'user': 1.40625}, 'percent': 0.0, 'ctx_switches': {'voluntary': 11191.0, 'involuntary': 0.0}}, 'mem': {'rss': 170450944.0}, 'library': 'langchain', 'runtime': 'python', 'platform': 'Windows-10-10.0.22621-SP0', 'sdk_version': '0.0.54', 'thread_count': 27.0, 'library_version': '0.0.327', 'runtime_version': '3.10.12', 'langchain_version': '0.0.327', 'py_implementation': 'CPython'}}, error=None, serialized=None, events=[{'name': 'start', 'time': '2023-12-04T03:25:26.160888'}, {'name': 'end', 'time': '2023-12-04T03:25:28.311379'}], inputs={'text': 'ðŸŒ‘ðŸŒ’ðŸŒ“ðŸŒ”ðŸŒ•'}, outputs={'output': {'type': 'AIMessageChunk', 'content': 'ðŸŒ•ðŸŒ”ðŸŒ“ðŸŒ’ðŸŒ‘', 'example': False, 'additional_kwargs': {}}}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=1, session_id=UUID('54ea1e16-85f8-4cd9-a2b7-4085a210240f'), child_run_ids=[UUID('e8c8ddb5-6eb7-46a3-a82a-8510e4b4344c'), UUID('a73e145d-0af4-4570-bedd-591bc217afdf')], child_runs=None, feedback_stats=None, app_path='/o/9da5a34e-f5e5-5974-bc8b-2c86a11d43cf/projects/p/54ea1e16-85f8-4cd9-a2b7-4085a210240f/r/6a802275-a598-461f-98c1-966bf902c25c', manifest_id=UUID('a303a376-634b-4d17-b29c-038a897d046a'), status='success', prompt_tokens=27, completion_tokens=15, total_tokens=42, first_token_time=datetime.datetime(2023, 12, 4, 3, 25, 28, 296858, tzinfo=datetime.timezone.utc), parent_run_ids=[], trace_id=UUID('6a802275-a598-461f-98c1-966bf902c25c'), dotted_order='20231204T032526160888Z6a802275-a598-461f-98c1-966bf902c25c')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List with the name filter to get runs with the assigned name\n",
    "next(client.list_runs(project_name=os.environ['LANGCHAIN_PROJECT'], filter='eq(name, \"StringReverse\")'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import agents, tools\n",
    "\n",
    "\n",
    "agent_executor = agents.initialize_agent(\n",
    "    llm=model,\n",
    "    tools=[tools.ReadFileTool(), tools.WriteFileTool(), tools.ListDirectoryTool()],\n",
    "    agent=agents.AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files in the current directory are:\n",
      "1. Customizing_Run_Names.ipynb\n",
      "2. Tracing_Nested_Calls_within_Tools.ipynb\n"
     ]
    }
   ],
   "source": [
    "with callbacks.collect_runs() as cb:\n",
    "    result = agent_executor.with_config({\"run_name\": \"File Agent\"}).invoke(\"What files are in the current directory?\")\n",
    "    run = cb.traced_runs[0]\n",
    "    print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved name: File Agent\n"
     ]
    }
   ],
   "source": [
    "callbacks.tracers.langchain.wait_for_all_tracers()\n",
    "print(f\"Saved name: {run.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An easy way to customize run names is to use the with_config syntax on your LangChain chain or runnable lambda. This makes it easier to understand a trace at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace link: https://smith.langchain.com/o/9da5a34e-f5e5-5974-bc8b-2c86a11d43cf/projects/p/54ea1e16-85f8-4cd9-a2b7-4085a210240f/r/9531b1f4-a03d-42e9-985b-3b48dac6eb18?poll=true\n"
     ]
    }
   ],
   "source": [
    "# Get trace link\n",
    "from langchain.callbacks import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled() as cb:\n",
    "    agent_executor.invoke({\"What files are in the current directory?\"})\n",
    "    url = cb.get_run_url()\n",
    "\n",
    "print(f\"Trace link: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
