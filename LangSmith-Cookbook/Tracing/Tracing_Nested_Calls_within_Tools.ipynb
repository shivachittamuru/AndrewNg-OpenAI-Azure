{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = os.environ['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import requests\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.tools import tool\n",
    "\n",
    "model = AzureChatOpenAI(temperature=0.0,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    deployment_name=\"gpt-35-turbo-16k\",\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type = openai.api_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Using the @tool decorator\n",
    "\n",
    "The `@tool` decorator is the most concise way to define a LangChain tool. To propagate callbacks through the tool function, simply include the \"callbacks\" option in the wrapped function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize_tool(url: str, callbacks: Callbacks = None):\n",
    "    \"\"\"Summarize a website.\"\"\"\n",
    "    text = requests.get(url).text\n",
    "    summary_chain = (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Summarize the following text:\\n<TEXT {uid}>\\n\" \"{text}\" \"\\n</TEXT {uid}>\"\n",
    "        ).partial(uid=lambda: uuid.uuid4())\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    ).with_config(run_name=\"Summarize Text\")\n",
    "    return summary_chain.invoke(\n",
    "        {\"text\": text},\n",
    "        {\"callbacks\": callbacks},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Subclass BaseTool\n",
    "\n",
    "By inheriting subclass `BaseTool`, you have more control over the class behavior and state management. You can choose to propagate callbacks by accepting a \"run_manager\" argument in your _run method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "import aiohttp\n",
    "import requests\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "def _default_summary_chain():\n",
    "    \"\"\"An LLM chain that summarizes the input text\"\"\"\n",
    "    return (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Summarize the following text:\\n<TEXT {uid}>\\n\" \"{text}\" \"\\n</TEXT {uid}>\"\n",
    "        ).partial(uid=lambda: uuid.uuid4())\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "        | StrOutputParser()\n",
    "    ).with_config(run_name=\"Summarize Text\")\n",
    "\n",
    "\n",
    "class CustomSummarizer(BaseTool):\n",
    "    name = \"summary_tool\"\n",
    "    description = \"summarize a website\"\n",
    "    summary_chain: Runnable = Field(default_factory=_default_summary_chain)\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        url: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        text = requests.get(url).text\n",
    "        callbacks = run_manager.get_child() if run_manager else None\n",
    "        return self.summary_chain.invoke(\n",
    "            {\"text\": text},\n",
    "            {\"callbacks\": callbacks},\n",
    "        )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        url: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                text = await response.text()\n",
    "        callbacks = run_manager.get_child() if run_manager else None\n",
    "        return await self.summary_chain.ainvoke(\n",
    "            {\"text\": text},\n",
    "            {\"callbacks\": callbacks},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=AzureChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.0, openai_api_key='abce878890064d9a93cee3ade1a8c809', openai_api_base='https://openaishiva.openai.azure.com/', deployment_name='gpt-35-turbo-16k', openai_api_type='azure', openai_api_version='2023-07-01-preview'), kwargs={'functions': [{'name': 'summarize_tool', 'description': 'summarize_tool(url: str, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) - Summarize a website.', 'parameters': {'title': 'summarize_toolSchemaSchema', 'type': 'object', 'properties': {'url': {'title': 'Url', 'type': 'string'}}, 'required': ['url']}}, {'name': 'summary_tool', 'description': 'summarize a website', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Agent\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are very powerful assistant, but bad at summarizing things.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the LLM with access to the appropriate function definitions\n",
    "tools = [summarize_tool, CustomSummarizer()]\n",
    "llm_with_tools = model.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_functions(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x.get(\"chat_history\") or [],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ").with_config(run_name=\"Summary Agent\")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the agent. All callbacks, including the LangSmith tracer, will be passed to the child runnables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What's this about? https://blog.langchain.dev/langchain-expression-language/\",\n",
       " 'output': 'The link you provided is to a blog post on the LangChain website. The blog post is about the LangChain Expression Language. It explains the syntax and features of the language and provides examples of how to use it. The post also includes links to related resources and a newsletter subscription form.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": f\"What's this about? https://blog.langchain.dev/langchain-expression-language/\"\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
