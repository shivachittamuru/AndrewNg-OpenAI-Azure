{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f10b4d1",
   "metadata": {},
   "source": [
    "### Splitting and Embedding Text Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8859749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cedb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('./churchill_speech.txt') as f:\n",
    "    churchill_speech = f.read()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0693ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 84\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.create_documents([churchill_speech])\n",
    "# print(chunks[2])\n",
    "# print(chunks[10].page_content)\n",
    "print(f'Now you have {len(chunks)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df4d686b",
   "metadata": {},
   "source": [
    "#### Embedding Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed819e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 4621\n",
      "Embedding Cost in USD: 0.001848\n"
     ]
    }
   ],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')\n",
    "    \n",
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdf79b3b",
   "metadata": {},
   "source": [
    "### Creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bdfd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings() # this won't work because only 1 chunk is supported currently.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "425c3c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(chunks[0].page_content)\n",
    "len(vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96f866ff",
   "metadata": {},
   "source": [
    "### Inserting the Embeddings into a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5215b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3b94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting all indexes\n",
    "indexes = pinecone.list_indexes()\n",
    "for i in indexes:\n",
    "    print('Deleting all indexes ... ', end='')\n",
    "    pinecone.delete_index(i)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9404a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index churchill-speech ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# creating an index\n",
    "index_name = 'churchill-speech'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Creating index {index_name} ...')\n",
    "    pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb84fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb0b01d",
   "metadata": {},
   "source": [
    "### Asking Questions (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4cccccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the\\nstreets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment', metadata={}), Document(page_content='end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing\\nconfidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we', metadata={}), Document(page_content='draw all the distinctions which we should like to do. If parachute landings were attempted and fierce\\nfighting attendant upon them followed, these unfortunate people would be far better out of the way,', metadata={}), Document(page_content='I return to the Army. In the long series of very fierce battles, now on this front, now on that, fighting\\non three fronts at once, battles fought by two or three divisions against an equal or somewhat larger', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "query = 'Where should we fight?'\n",
    "result = vector_store.similarity_search(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bdacf56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and\n",
      "--------------------------------------------------\n",
      "front, now on that, fighting\n",
      "--------------------------------------------------\n",
      "end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing\n",
      "--------------------------------------------------\n",
      "When we consider how much greater would be our advantage in defending the air above this Island\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f155a46",
   "metadata": {},
   "source": [
    "### Answering in Natural Language using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cf0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf8e6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, it seems that the speaker is declaring their determination to fight in various locations including beaches, landing grounds, fields, France, seas and oceans. The context doesn't provide information about a specific situation, so it's unclear who the speaker is referring to or what they are fighting for.\n"
     ]
    }
   ],
   "source": [
    "query = 'Where should we fight?'\n",
    "answer = chain.run(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c9ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The king of Belgium at that time was King Leopold.\n"
     ]
    }
   ],
   "source": [
    "query = 'Who was the king of Belgium at that time?'\n",
    "# query = 'What about the French Armies??'\n",
    "answer = chain.run(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8688ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
