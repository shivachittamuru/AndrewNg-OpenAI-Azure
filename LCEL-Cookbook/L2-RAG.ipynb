{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = os.environ['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Shiva studied at UMD, Go Bulldogs!\", \"Shiva grew up in Hyderabad, India\", \"Shiva works at Microsoft\"],\n",
    "    embedding=OpenAIEmbeddings(chunk_size=10)\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = AzureChatOpenAI(temperature=0.3,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type = openai.api_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shiva grew up in Hyderabad, India.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "chain.invoke(\"where did Shiva grow up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shiva's birthplace is Hyderabad, India.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is Shiva's birthplace?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bob', 25, 6.0), ('Alice', 30, 5.5), ('Charlie', 35, 5.9)]\n",
      "30\n",
      "25\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Understanding itemgetter -  a handy tool for extracting specific values from iterables, making it easier to work with and manipulate them.\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "people = [('Alice', 30, 5.5), ('Bob', 25, 6.0), ('Charlie', 35, 5.9)]\n",
    "\n",
    "# Use itemgetter to get the second element (age) from each tuple and create get_age function\n",
    "get_age = itemgetter(1)\n",
    "\n",
    "# Now you can use get_age as a key function for sorting\n",
    "sorted_people = sorted(people, key=get_age)\n",
    "\n",
    "print(sorted_people)\n",
    "\n",
    "for p in people:\n",
    "    print(get_age(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'शिवा माइक्रोसॉफ्ट में काम करते हैं।'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did shiva work\", \"language\": \"hindi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "condense_question_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(condense_question_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(answer_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Human: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | model\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Shiva was employed at Microsoft.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did Shiva work?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  chat_history: RunnableLambda(...)\n",
       "                | RunnableLambda(...)\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")\n",
    "\n",
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "loaded_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory(\n",
    "#     return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    "# )\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    ")\n",
    "\n",
    "# Now we calculate the standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | model\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "\n",
    "# Now we retrieve the documents\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | model,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "# And now we put it all together!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='Shiva was employed at Microsoft.'),\n",
       " 'docs': [Document(page_content='Shiva works at Microsoft'),\n",
       "  Document(page_content='Shiva grew up in Hyderabad, India'),\n",
       "  Document(page_content='Shiva studied at UMD, Go Bulldogs!')]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"where did Shiva work?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='where did Shiva work?'),\n",
       "  AIMessage(content='Shiva was employed at Microsoft.')]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the memory does not save automatically\n",
    "# This will be improved in the future\n",
    "# For now you need to save it yourself\n",
    "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ConversationBufferMemory.load_memory_variables of ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='where did Shiva work?'), AIMessage(content='Shiva was employed at Microsoft.')]), return_messages=True)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HumanMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shchitt\\OneDrive - Microsoft\\Desktop\\OpenAI\\AndrewNg-OpenAI-Azure\\LCEL-Cookbook\\L2-RAG.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inputs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwho is the current ceo of that company?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m final_chain\u001b[39m.\u001b[39;49minvoke(inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[1;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[0;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   1156\u001b[0m             patch_config(\n\u001b[0;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1158\u001b[0m             ),\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[0;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1664\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[0;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1663\u001b[0m         ]\n\u001b[1;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1664\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[0;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1663\u001b[0m         ]\n\u001b[1;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[1;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[0;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   1156\u001b[0m             patch_config(\n\u001b[0;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1158\u001b[0m             ),\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[0;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1664\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[0;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1663\u001b[0m         ]\n\u001b[1;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:1664\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[0;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1663\u001b[0m         ]\n\u001b[1;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:2231\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2229\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 2231\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[0;32m   2232\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke,\n\u001b[0;32m   2233\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   2234\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc),\n\u001b[0;32m   2235\u001b[0m     )\n\u001b[0;32m   2236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse `ainvoke` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2240\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:668\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    662\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    663\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m    664\u001b[0m     run_type\u001b[39m=\u001b[39mrun_type,\n\u001b[0;32m    665\u001b[0m     name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    666\u001b[0m )\n\u001b[0;32m    667\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m    669\u001b[0m         func, \u001b[39minput\u001b[39m, config, run_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    670\u001b[0m     )\n\u001b[0;32m    671\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    672\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\config.py:263\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    262\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[1;32m--> 263\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\base.py:2164\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[0;32m   2159\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2160\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[0;32m   2161\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[0;32m   2162\u001b[0m     config: RunnableConfig,\n\u001b[0;32m   2163\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m-> 2164\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, config, run_manager)\n\u001b[0;32m   2165\u001b[0m     \u001b[39m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[0;32m   2166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32mc:\\Users\\shchitt\\AppData\\Local\\anaconda3\\envs\\llms\\lib\\site-packages\\langchain\\schema\\runnable\\config.py:263\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    262\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[1;32m--> 263\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\shchitt\\OneDrive - Microsoft\\Desktop\\OpenAI\\AndrewNg-OpenAI-Azure\\LCEL-Cookbook\\L2-RAG.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loaded_memory \u001b[39m=\u001b[39m RunnablePassthrough\u001b[39m.\u001b[39massign(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     chat_history\u001b[39m=\u001b[39mRunnableLambda(memory\u001b[39m.\u001b[39mload_memory_variables) \u001b[39m|\u001b[39m itemgetter(\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Now we calculate the standalone question\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m standalone_question \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstandalone_question\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m x: _format_chat_history(x[\u001b[39m\"\u001b[39;49m\u001b[39mchat_history\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m|\u001b[39m CONDENSE_QUESTION_PROMPT\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m|\u001b[39m model\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m|\u001b[39m StrOutputParser(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Now we retrieve the documents\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m retrieved_documents \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdocs\u001b[39m\u001b[39m\"\u001b[39m: itemgetter(\u001b[39m\"\u001b[39m\u001b[39mstandalone_question\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m|\u001b[39m retriever,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mstandalone_question\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m }\n",
      "\u001b[1;32mc:\\Users\\shchitt\\OneDrive - Microsoft\\Desktop\\OpenAI\\AndrewNg-OpenAI-Azure\\LCEL-Cookbook\\L2-RAG.ipynb Cell 22\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m buffer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m dialogue_turn \u001b[39min\u001b[39;00m chat_history:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     human \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHuman: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m dialogue_turn[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     ai \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAssistant: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m dialogue_turn[\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shchitt/OneDrive%20-%20Microsoft/Desktop/OpenAI/AndrewNg-OpenAI-Azure/LCEL-Cookbook/L2-RAG.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     buffer \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([human, ai])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HumanMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"who is the current ceo of that company?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
